# Execution Trace Generation

Token datasets are generated by first running the A* algrithm on randomly generated maze or Sokoban task instances.
For each A* execution a trace dictionary is generated an stored in MongoDB.
Subsequently these trace dictionaries are mapped to token sequences.
This code release includes the final token sequence datasets.

## Generating A* execution traces

Execution trace generation is implemented in `searchformer.maze` for maze tasks and `searchformer.sokoban` for Sokoban tasks.
Both modules use the A* implementation in `searchformer.astar`.

For example, A* execution traces for `10x10` mazes are generated with the command

```
python -m searchformer.maze generate --width 10 --height 10
```

This command can be run in parallel in a distributed fashion and the python script will write data to the MongoDB instance.
Uniqueness of each generated maze and a proper training-test split is ensured at the database level.
All hyper-parameters for this generation script can be listed with `python -m searchformer.maze generate --help`.

For Sokoban, execution traces are generated in a similar fashion by calling the `generate` command of `searchformer.sokoban`. 
All hyper-parameters for this generation script can be listed with `python -m searchformer.sokoban generate --help`.
In the main paper, puzzles have a size of `7x7` with 2 boxes and 2 wall cells.

## Tokenizing execution traces

A generated execution trace is tokenized by running multiple tokenization workers concurrently on a different slice of the execution trace dataset.
These tokenization workers generate token datasets that are of the same type for each task and are used directly when training each Transformer model.
For maze tasks and Sokoban puzzles we use one tokenization pattern each.

To ensure that each worker tokenizes a different dataset slice, its rank index and world size parameters need to be set. 
A world size of `n` specifies that `n` workers tokenize the trace dataset and each worker is indexed with a rank index ranging from `0...n-1`.

For example, to launch worker `0` (out of `100` in total) to tokenize a `10x10` maze dataset generated with deterministic A* run

```
python -m searchformer.maze tokenize --width 10 --height 10 --deterministic --rank 0 --world-size 100
```

Similarly, the Sokoban trace data can be tokenized by running the command `python -m searchformer.sokoban tokenize`.

## Reading token data

An example demonstrating how to read the token datasets can be found in the notebook [TokenDatasets.ipynb](../notebook/TokenDatasets.ipynb).

## Related commands

The following commands can be used to generate maze and Sokoban execution trace data with A* search.

```
python -m searchformer.maze generate --help
python -m searchformer.maze drop-dataset --help
python -m searchformer.maze tokenize --help
python -m searchformer.sokoban generate --help
python -m searchformer.sokoban drop-dataset --help
python -m searchformer.sokoban tokenize --help
```