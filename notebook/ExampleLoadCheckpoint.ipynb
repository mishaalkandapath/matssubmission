{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Prompt a Checkpoint\n",
    "\n",
    "This notebook demonstrates how to reconstruct a model from a file checkpoint. \n",
    "To load the vocabulary and tokenizer used to train this model correctly, this notebook assumes that the corresponding maze datasets are loaded into MongoDB correctly, as outlined in [TokenDatasets.ipynb](TokenDatasets.ipynb).\n",
    "\n",
    "A single checkpoint holds data about\n",
    "* Hyper-parameters used for training (excluding the token vocabulary, which is stored together with the corresponding token dataset).\n",
    "* All model parameters\n",
    "* Optimizer state\n",
    "* Number of gradient steps at which the model was solved\n",
    "\n",
    "This notebook only outlines how a model can be reconstructed from a checkpoint file.\n",
    "To use any of the other workflows included in this code base, the checkpoint files must be be first imported into MongoDB.\n",
    "In this notebook we focus on the checkpoint resulting from the run `maze-sweep-rep-nondet-small-0` and assume that the file `maze-sweep-rep-nondet-small-0.ckpt` is present at the project's root directory.\n",
    "This checkpoint file can be downloaded [here](https://dl.fbaipublicfiles.com/searchformer/ckptDB/maze-sweep-rep-nondet-small-0.ckpt). \n",
    "The file [`checkpoint_index.csv`](../doc.checkpoint_index.csv) lists all released checkpoints and their corresponding download link."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First different modules are imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append(\"..\")\n",
    "\n",
    "import logging\n",
    "import torch\n",
    "from searchformer.train import Checkpoint\n",
    "from searchformer.transformer import EncoderDecoderConfig, sample_probability\n",
    "from searchformer.trace import DictTokenizer, TokenizedDataset\n",
    "\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(levelname)s - %(asctime)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the checkpoint file `../maze-sweep-rep-nondet-small-0.ckpt` and printing the training configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': 'maze-sweep-rep-nondet-small-0',\n",
       " 'data': {'train_name': 'maze.10-by-10-nondeterministic.simple',\n",
       "  'test_name': 'maze.10-by-10-nondeterministic.simple',\n",
       "  'batch_size': 8,\n",
       "  'plan_only': False,\n",
       "  'num_train_sequences': 50000,\n",
       "  'num_test_sequences': 100000,\n",
       "  'load_batch_size': 10000,\n",
       "  'num_workers': 2},\n",
       " 'encoder': 'enc-s',\n",
       " 'decoder': 'dec-s',\n",
       " 'optimizer': {'lr': 0.00025,\n",
       "  'lr_schedule': 'cosine',\n",
       "  'train_steps': 400000,\n",
       "  'warmup': 2000,\n",
       "  'beta_0': 0.9,\n",
       "  'beta_1': 0.99,\n",
       "  'cycle_length': 1.0,\n",
       "  'cosine_theta': 1.0,\n",
       "  'lr_min_ratio': 0.1},\n",
       " 'log_interval': 1000,\n",
       " 'eval_interval': 40000}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = Checkpoint.from_file(\"../maze-sweep-rep-nondet-small-0.ckpt\")\n",
    "ckpt.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First loading the tokenized dataset and constructing a `DictTokenizer` object. \n",
    "This object is used to map word token sequences to integer lists.\n",
    "Subsequently, an `EncoderDecoderConfig` object is constructed which holds all network architecture model parameters.\n",
    "From this object the actual encoder-decoder Transformer is constructed and the model parameters (state dictionary) are loaded in.\n",
    "The example below runs inference on CPU for the smallest model and shortest sequences to reduce compute requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2024-04-26 13:56:08 - root - Connecting to mongodb://localhost:27017/mongo\n",
      "INFO - 2024-04-26 13:56:08 - root - Vocabulary size: 118\n",
      "DEBUG - 2024-04-26 13:56:08 - root - Creating block: n_heads=3, dim=192.\n",
      "DEBUG - 2024-04-26 13:56:08 - root - Creating block: n_heads=3, dim=192.\n",
      "DEBUG - 2024-04-26 13:56:08 - root - Creating block: n_heads=3, dim=192.\n",
      "DEBUG - 2024-04-26 13:56:08 - root - Creating block: n_heads=3, dim=192.\n",
      "DEBUG - 2024-04-26 13:56:08 - root - Creating block: n_heads=3, dim=192.\n",
      "DEBUG - 2024-04-26 13:56:08 - root - Creating block: n_heads=3, dim=192.\n",
      "DEBUG - 2024-04-26 13:56:08 - root - Creating block: n_heads=3, dim=192.\n",
      "DEBUG - 2024-04-26 13:56:08 - root - Creating block: n_heads=3, dim=192.\n",
      "DEBUG - 2024-04-26 13:56:08 - root - Creating block: n_heads=3, dim=192.\n",
      "DEBUG - 2024-04-26 13:56:08 - root - Creating block: n_heads=3, dim=192.\n",
      "DEBUG - 2024-04-26 13:56:08 - root - Creating block: n_heads=3, dim=192.\n",
      "DEBUG - 2024-04-26 13:56:08 - root - Creating block: n_heads=3, dim=192.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load vocabulary from tokenized dataset. This is needed to load the training token vocabulary and a test prompt.\n",
    "tok_dataset = TokenizedDataset(ckpt.config_obj.data.train_name)\n",
    "# Load tokenizer mapping tokens to indices.\n",
    "tokenizer = DictTokenizer(tok_dataset.vocabulary)\n",
    "# Construct model config object.\n",
    "enc_dec_config = EncoderDecoderConfig.from_name(\n",
    "    enc_name=ckpt.config_obj.encoder,\n",
    "    dec_name=ckpt.config_obj.decoder,\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    ")\n",
    "# Construct model from config.\n",
    "model = enc_dec_config.construct_model()\n",
    "# Loading trained weights into model.\n",
    "model.load_state_dict(ckpt.model_only_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code segment loads the first test prompt and prints it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG - 2024-04-26 13:56:08 - root - Loading all ids from Collection(Database(MongoClient(host=['localhost:27017'], document_class=dict, tz_aware=False, connect=True, sockettimeoutms=1800000, connecttimeoutms=1800000), 'tokenSeqDB'), 'maze.10-by-10-nondeterministic.simple.meta.test') ...\n",
      "DEBUG - 2024-04-26 13:56:08 - root - Finished loading.\n",
      "DEBUG - 2024-04-26 13:56:08 - root - Iterating over 1 ids.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: \n",
      "\tstart 3 6 \n",
      "\tgoal  4 2 \n",
      "\twall  0 0 \n",
      "\twall  3 0 \n",
      "\twall  4 0 \n",
      "\twall  2 1 \n",
      "\twall  4 1 \n",
      "\twall  5 1 \n",
      "\twall  9 1 \n",
      "\twall  0 2 \n",
      "\twall  1 2 \n",
      "\twall  2 2 \n",
      "\twall  6 2 \n",
      "\twall  7 2 \n",
      "\twall  5 3 \n",
      "\twall  6 3 \n",
      "\twall  7 3 \n",
      "\twall  8 3 \n",
      "\twall  9 3 \n",
      "\twall  1 4 \n",
      "\twall  2 4 \n",
      "\twall  3 4 \n",
      "\twall  9 4 \n",
      "\twall  3 5 \n",
      "\twall  4 5 \n",
      "\twall  6 5 \n",
      "\twall  5 6 \n",
      "\twall  6 6 \n",
      "\twall  9 6 \n",
      "\twall  0 7 \n",
      "\twall  2 7 \n",
      "\twall  4 7 \n",
      "\twall  6 8 \n",
      "\twall  9 8 \n",
      "\twall  2 9 \n",
      "\twall  3 9 \n",
      "\twall  4 9 \n",
      "\twall  6 9 \n",
      "\twall  8 9\n"
     ]
    }
   ],
   "source": [
    "test_trace_id_list = tok_dataset.test_ids\n",
    "test_trace_id_list.sort()\n",
    "test_trace = next(iter(tok_dataset.test_it(test_trace_id_list[:1])))[0]\n",
    "\n",
    "prompt_str = \" \".join(test_trace.prompt)\n",
    "prompt_str = prompt_str.replace(\"start\", \"\\n\\tstart\")\n",
    "prompt_str = prompt_str.replace(\"wall\", \"\\n\\twall \")\n",
    "prompt_str = prompt_str.replace(\"goal\", \"\\n\\tgoal \")\n",
    "print(\"Prompt: \" + prompt_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code segment maps the prompt to an integer tensor and then generates a response sequence. \n",
    "This response sequence (a integer tensor) is then decoded into a token sequence and printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG - 2024-04-26 13:56:13 - root - Rollout 200 steps, 0 seq. complete.\n",
      "INFO - 2024-04-26 13:56:15 - root - Rollout length: 283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n",
      "\tbos\n",
      "\tcreate 3 6 c0 c5 \n",
      "\tclose  3 6 c0 c5 \n",
      "\tcreate 3 7 c1 c6 \n",
      "\tcreate 4 6 c1 c4 \n",
      "\tcreate 2 6 c1 c6 \n",
      "\tclose  4 6 c1 c4 \n",
      "\tclose  3 7 c1 c6 \n",
      "\tcreate 3 8 c2 c7 \n",
      "\tclose  2 6 c1 c6 \n",
      "\tcreate 2 5 c2 c5 \n",
      "\tcreate 1 6 c2 c7 \n",
      "\tclose  2 5 c2 c5 \n",
      "\tcreate 1 5 c3 c6 \n",
      "\tclose  1 5 c3 c6 \n",
      "\tcreate 0 5 c4 c7 \n",
      "\tclose  1 6 c2 c7 \n",
      "\tcreate 1 7 c3 c8 \n",
      "\tcreate 0 6 c3 c8 \n",
      "\tclose  3 8 c2 c7 \n",
      "\tcreate 2 8 c3 c8 \n",
      "\tcreate 4 8 c3 c6 \n",
      "\tclose  4 8 c3 c6 \n",
      "\tcreate 5 8 c4 c7 \n",
      "\tclose  2 8 c3 c8 \n",
      "\tcreate 1 8 c4 c9 \n",
      "\tclose  1 7 c3 c8 \n",
      "\tclose  0 5 c4 c7 \n",
      "\tcreate 0 4 c5 c6 \n",
      "\tclose  5 8 c4 c7 \n",
      "\tcreate 5 9 c5 c8 \n",
      "\tcreate 5 7 c5 c6 \n",
      "\tclose  0 4 c5 c6 \n",
      "\tcreate 0 3 c6 c5 \n",
      "\tclose  0 6 c3 c8 \n",
      "\tclose  0 3 c6 c5 \n",
      "\tcreate 1 3 c7 c4 \n",
      "\tclose  5 7 c5 c6 \n",
      "\tcreate 6 7 c6 c7 \n",
      "\tclose  1 3 c7 c4 \n",
      "\tcreate 2 3 c8 c3 \n",
      "\tclose  2 3 c8 c3 \n",
      "\tcreate 3 3 c9 c2 \n",
      "\tclose  3 3 c9 c2 \n",
      "\tcreate 4 3 c10 c1 \n",
      "\tcreate 3 2 c10 c1 \n",
      "\tclose  4 3 c10 c1 \n",
      "\tcreate 4 2 c11 c0 \n",
      "\tcreate 4 4 c11 c2 \n",
      "\tclose  2 2 c9 c0 \n",
      "\tplan   3 6 \n",
      "\tplan   2 6 \n",
      "\tplan   2 5 \n",
      "\tplan   1 5 \n",
      "\tplan   0 5 \n",
      "\tplan   0 4 \n",
      "\tplan   0 3 \n",
      "\tplan   1 3 \n",
      "\tplan   2 3 \n",
      "\tplan   3 3 \n",
      "\tplan   4 3 \n",
      "\tplan   4 2 \n",
      "\teos\n"
     ]
    }
   ],
   "source": [
    "prompt_tokens = tokenizer.encode(test_trace.prompt)\n",
    "prompt_tokens_tensor = torch.Tensor(prompt_tokens).long()\n",
    "response = model.rollout(\n",
    "    prompt=prompt_tokens_tensor,\n",
    "    bos_idx=tokenizer.bos,\n",
    "    eos_idx=tokenizer.eos,\n",
    "    max_rollout_len=2000,\n",
    "    sample_fn=sample_probability,\n",
    ")\n",
    "response_token_list = tokenizer.decode(response[0].tolist())\n",
    "print(\"Response:\" + \" \".join(response_token_list).replace(\"bos \", \"\\n\\tbos\").replace(\"eos\", \"\\n\\teos\").replace(\"create\", \"\\n\\tcreate\").replace(\"close\", \"\\n\\tclose \").replace(\"plan \", \"\\n\\tplan   \"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
